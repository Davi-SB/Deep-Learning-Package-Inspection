{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd13597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[39 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/requirements.py\", line 36, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/_parser.py\", line 62, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/_parser.py\", line 80, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/_parser.py\", line 124, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/_parser.py\", line 145, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/_tokenizer.py\", line 168, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 35, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-dv2cmwqs/tensorflow-gpu_ef4d4942d4934f6c93d27797e13c39ca/setup.py\", line 40, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/setuptools/__init__.py\", line 114, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/setuptools/__init__.py\", line 85, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/setuptools/dist.py\", line 758, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/setuptools/dist.py\", line 382, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._normalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/setuptools/dist.py\", line 400, in _normalize_requires\n",
      "  \u001b[31m   \u001b[0m     self.install_requires = list_(map(str, _reqs.parse(install_requires)))\n",
      "  \u001b[31m   \u001b[0m   File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/packaging/requirements.py\", line 38, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Requirement already satisfied: nvidia-cudnn-cu12 in ./.venv/lib/python3.10/site-packages (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cudnn-cu12) (12.9.1.4)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-11.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu\n",
    "!pip install nvidia-cudnn-cu12\n",
    "!pip install Pillow\n",
    "\n",
    "# Rodar um \n",
    "# conda install -c conda-forge cudatoolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae616ab5",
   "metadata": {},
   "source": [
    "## Modelo para Side\n",
    "### Importando o Modelo pré treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ddb2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 11:36:49.450061: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-04 11:36:49.465915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751639809.485363   28866 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751639809.491642   28866 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751639809.505824   28866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751639809.505843   28866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751639809.505845   28866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751639809.505847   28866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-04 11:36:49.510343: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1751639811.573965   28866 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1403 MB memory:  -> device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:05:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(320,576,3),\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f1326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb42421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2201263",
   "metadata": {},
   "source": [
    "### Adicionando Camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22707d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape side: (540, 960, 3)\n",
      "Shape top: (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_side = Image.open('./dataset-desafio/side/damaged/0185507921789_side.png')\n",
    "img_array_side = np.array(img_side)\n",
    "\n",
    "img_top = Image.open('./dataset-desafio/top/damaged/0185507921789_top.png')\n",
    "img_array_top = np.array(img_top)\n",
    "\n",
    "print(\"Shape side:\", img_array_side.shape)\n",
    "print(\"Shape top:\", img_array_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b83d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,715,201</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,715,201\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m513\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(320,576,3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation= 'sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs,outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052588ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', metrics=['accuracy','Precision','Recall', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e514eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 2 classes.\n",
      "Using 144 files for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 2 classes.\n",
      "Using 36 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_dt = keras.utils.image_dataset_from_directory(\n",
    "    \"./dataset-desafio/side\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    batch_size=4,\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(320,576),\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "valid_dt = keras.utils.image_dataset_from_directory(\n",
    "    \"./dataset-desafio/side\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    batch_size=4,\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(320,576),\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c1296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751639834.383543   30004 service.cc:152] XLA service 0x7f009000d290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751639834.383573   30004 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce MX450, Compute Capability 7.5\n",
      "2025-07-04 11:37:14.468489: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751639834.833935   30004 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "2025-07-04 11:37:15.435714: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.39 = (f32[4,64,320,576]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,3,320,576]{3,2,1,0} %bitcast.1430, f32[64,3,3,3]{3,2,1,0} %bitcast.1437, f32[64]{0} %bitcast.1439), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block1_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:17.390895: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.40 = (f32[4,64,320,576]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.1444, f32[64,64,3,3]{3,2,1,0} %bitcast.1451, f32[64]{0} %bitcast.1453), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block1_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:18.992416: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.41 = (f32[4,128,160,288]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,160,288]{3,2,1,0} %bitcast.1460, f32[128,64,3,3]{3,2,1,0} %bitcast.1467, f32[128]{0} %bitcast.1469), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block2_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:20.756728: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.42 = (f32[4,128,160,288]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,160,288]{3,2,1,0} %bitcast.1474, f32[128,128,3,3]{3,2,1,0} %bitcast.1481, f32[128]{0} %bitcast.1483), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block2_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:22.032533: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.43 = (f32[4,256,80,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,80,144]{3,2,1,0} %bitcast.1489, f32[256,128,3,3]{3,2,1,0} %bitcast.1496, f32[256]{0} %bitcast.1498), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block3_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:22.260861: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:37:23.690130: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.44 = (f32[4,256,80,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,80,144]{3,2,1,0} %bitcast.1503, f32[256,256,3,3]{3,2,1,0} %bitcast.1510, f32[256]{0} %bitcast.1512), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block3_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:24.104946: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:37:24.828869: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.46 = (f32[4,512,40,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,40,72]{3,2,1,0} %bitcast.1532, f32[512,256,3,3]{3,2,1,0} %bitcast.1539, f32[512]{0} %bitcast.1541), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block4_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:25.013805: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:37:26.562590: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.47 = (f32[4,512,40,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,40,72]{3,2,1,0} %bitcast.1546, f32[512,512,3,3]{3,2,1,0} %bitcast.1553, f32[512]{0} %bitcast.1555), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block4_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:27.225600: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:37:27.225655: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:37:27.641273: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[4,512,20,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,20,36]{3,2,1,0} %bitcast.1575, f32[512,512,3,3]{3,2,1,0} %bitcast.1582, f32[512]{0} %bitcast.1584), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block5_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:37:27.832395: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1751639848.661401   30004 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 327ms/step - AUC: 0.5088 - Precision: 0.5205 - Recall: 0.4561 - accuracy: 0.5488 - loss: 1.0583 - val_AUC: 0.4643 - val_Precision: 0.6400 - val_Recall: 0.7273 - val_accuracy: 0.5833 - val_loss: 0.8356\n",
      "Epoch 2/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 294ms/step - AUC: 0.4502 - Precision: 0.4943 - Recall: 0.5522 - accuracy: 0.4716 - loss: 0.8577 - val_AUC: 0.5016 - val_Precision: 0.5714 - val_Recall: 0.3636 - val_accuracy: 0.4444 - val_loss: 0.8294\n",
      "Epoch 3/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - AUC: 0.5756 - Precision: 0.5807 - Recall: 0.5654 - accuracy: 0.5619 - loss: 0.7376 - val_AUC: 0.5390 - val_Precision: 0.6364 - val_Recall: 0.3182 - val_accuracy: 0.4722 - val_loss: 0.7936\n",
      "Epoch 4/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.5495 - Precision: 0.5800 - Recall: 0.5609 - accuracy: 0.5244 - loss: 0.7036 - val_AUC: 0.6006 - val_Precision: 0.6667 - val_Recall: 0.5455 - val_accuracy: 0.5556 - val_loss: 0.7114\n",
      "Epoch 5/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.5955 - Precision: 0.5738 - Recall: 0.5956 - accuracy: 0.5594 - loss: 0.6813 - val_AUC: 0.6250 - val_Precision: 0.8000 - val_Recall: 0.1818 - val_accuracy: 0.4722 - val_loss: 0.8623\n",
      "Epoch 6/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.6587 - Precision: 0.5869 - Recall: 0.5266 - accuracy: 0.5731 - loss: 0.6590 - val_AUC: 0.6477 - val_Precision: 0.6923 - val_Recall: 0.8182 - val_accuracy: 0.6667 - val_loss: 0.6149\n",
      "Epoch 7/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.6715 - Precision: 0.6565 - Recall: 0.6650 - accuracy: 0.6673 - loss: 0.6456 - val_AUC: 0.6916 - val_Precision: 0.7222 - val_Recall: 0.5909 - val_accuracy: 0.6111 - val_loss: 0.6190\n",
      "Epoch 8/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.7517 - Precision: 0.7263 - Recall: 0.7822 - accuracy: 0.7403 - loss: 0.5907 - val_AUC: 0.7143 - val_Precision: 0.7308 - val_Recall: 0.8636 - val_accuracy: 0.7222 - val_loss: 0.5744\n",
      "Epoch 9/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.8022 - Precision: 0.7407 - Recall: 0.8436 - accuracy: 0.7684 - loss: 0.5510 - val_AUC: 0.7484 - val_Precision: 0.7500 - val_Recall: 0.4091 - val_accuracy: 0.5556 - val_loss: 0.6466\n",
      "Epoch 10/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 298ms/step - AUC: 0.8468 - Precision: 0.7568 - Recall: 0.8495 - accuracy: 0.7845 - loss: 0.4929 - val_AUC: 0.7938 - val_Precision: 0.8421 - val_Recall: 0.7273 - val_accuracy: 0.7500 - val_loss: 0.5654\n",
      "Epoch 11/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.8324 - Precision: 0.7528 - Recall: 0.8069 - accuracy: 0.7710 - loss: 0.5407 - val_AUC: 0.8068 - val_Precision: 0.8333 - val_Recall: 0.4545 - val_accuracy: 0.6111 - val_loss: 0.6243\n",
      "Epoch 12/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.8882 - Precision: 0.8845 - Recall: 0.8366 - accuracy: 0.8675 - loss: 0.4844 - val_AUC: 0.8312 - val_Precision: 0.8750 - val_Recall: 0.3182 - val_accuracy: 0.5556 - val_loss: 0.7126\n",
      "Epoch 13/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.8952 - Precision: 0.8686 - Recall: 0.7913 - accuracy: 0.8338 - loss: 0.4596 - val_AUC: 0.8393 - val_Precision: 0.8571 - val_Recall: 0.8182 - val_accuracy: 0.8056 - val_loss: 0.5242\n",
      "Epoch 14/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.9073 - Precision: 0.7645 - Recall: 0.8533 - accuracy: 0.7956 - loss: 0.4458 - val_AUC: 0.8474 - val_Precision: 0.8571 - val_Recall: 0.8182 - val_accuracy: 0.8056 - val_loss: 0.5189\n",
      "Epoch 15/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 344ms/step - AUC: 0.9040 - Precision: 0.8374 - Recall: 0.8341 - accuracy: 0.8329 - loss: 0.4234 - val_AUC: 0.8474 - val_Precision: 0.8889 - val_Recall: 0.7273 - val_accuracy: 0.7778 - val_loss: 0.5545\n",
      "Epoch 16/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 653ms/step - AUC: 0.9021 - Precision: 0.7943 - Recall: 0.8564 - accuracy: 0.8237 - loss: 0.4321 - val_AUC: 0.8523 - val_Precision: 0.8400 - val_Recall: 0.9545 - val_accuracy: 0.8611 - val_loss: 0.4822\n",
      "Epoch 17/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - AUC: 0.9278 - Precision: 0.8096 - Recall: 0.8691 - accuracy: 0.8310 - loss: 0.4020 - val_AUC: 0.8539 - val_Precision: 0.8333 - val_Recall: 0.9091 - val_accuracy: 0.8333 - val_loss: 0.4822\n",
      "Epoch 18/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.9123 - Precision: 0.8113 - Recall: 0.8616 - accuracy: 0.8222 - loss: 0.4168 - val_AUC: 0.8523 - val_Precision: 0.8947 - val_Recall: 0.7727 - val_accuracy: 0.8056 - val_loss: 0.5154\n",
      "Epoch 19/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.9242 - Precision: 0.8588 - Recall: 0.8664 - accuracy: 0.8506 - loss: 0.4064 - val_AUC: 0.8636 - val_Precision: 0.7500 - val_Recall: 0.9545 - val_accuracy: 0.7778 - val_loss: 0.4890\n",
      "Epoch 20/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.9025 - Precision: 0.8443 - Recall: 0.8756 - accuracy: 0.8486 - loss: 0.3940 - val_AUC: 0.8604 - val_Precision: 0.9048 - val_Recall: 0.8636 - val_accuracy: 0.8611 - val_loss: 0.4809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f017dcef310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dt,\n",
    "          validation_data=valid_dt,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61047827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 11:43:09.939739: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.39 = (f32[4,64,320,576]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,3,320,576]{3,2,1,0} %bitcast.5194, f32[64,3,3,3]{3,2,1,0} %bitcast.5201, f32[64]{0} %bitcast.6462), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block1_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:11.779589: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.40 = (f32[4,64,320,576]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.6514, f32[64,64,3,3]{3,2,1,0} %bitcast.5219, f32[64]{0} %bitcast.6554), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block1_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:13.398761: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.41 = (f32[4,128,160,288]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,160,288]{3,2,1,0} %bitcast.6606, f32[128,64,3,3]{3,2,1,0} %bitcast.5239, f32[128]{0} %bitcast.6646), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block2_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:15.241403: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.42 = (f32[4,128,160,288]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,160,288]{3,2,1,0} %bitcast.6699, f32[128,128,3,3]{3,2,1,0} %bitcast.5257, f32[128]{0} %bitcast.6739), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block2_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:16.485200: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.43 = (f32[4,256,80,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,80,144]{3,2,1,0} %bitcast.6791, f32[256,128,3,3]{3,2,1,0} %bitcast.5276, f32[256]{0} %bitcast.6831), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block3_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:16.716882: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:43:18.200424: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.44 = (f32[4,256,80,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,80,144]{3,2,1,0} %bitcast.6880, f32[256,256,3,3]{3,2,1,0} %bitcast.5294, f32[256]{0} %bitcast.6920), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block3_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:18.618392: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:43:19.355664: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.46 = (f32[4,512,40,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,40,72]{3,2,1,0} %bitcast.7056, f32[512,256,3,3]{3,2,1,0} %bitcast.5331, f32[512]{0} %bitcast.7096), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block4_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:19.540733: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:43:21.132874: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.47 = (f32[4,512,40,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,40,72]{3,2,1,0} %bitcast.7145, f32[512,512,3,3]{3,2,1,0} %bitcast.5349, f32[512]{0} %bitcast.7185), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block4_conv2_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:21.796265: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-04 11:43:22.103004: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[4,512,20,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,512,20,36]{3,2,1,0} %bitcast.7321, f32[512,512,3,3]{3,2,1,0} %bitcast.5386, f32[512]{0} %bitcast.7361), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/vgg16_1/block5_conv1_1/convolution\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-04 11:43:34.998866: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bw-filter.14 = (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.6514, f32[4,64,320,576]{3,2,1,0} %bitcast.6558), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/vgg16_1/block1_conv2_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16924672 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-07-04 11:43:34.999415: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bw-filter.14 = (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.6514, f32[4,64,320,576]{3,2,1,0} %bitcast.6558), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/vgg16_1/block1_conv2_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16924672 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_28866/3153805891.py\", line 6, in <module>\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter.14 = (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.6514, f32[4,64,320,576]{3,2,1,0} %bitcast.6558), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/vgg16_1/block1_conv2_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16924672 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_39582]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRMSprop(learning_rate\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m),\n\u001b[1;32m      4\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_28866/3153805891.py\", line 6, in <module>\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter.14 = (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,320,576]{3,2,1,0} %bitcast.6514, f32[4,64,320,576]{3,2,1,0} %bitcast.6558), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/vgg16_1/block1_conv2_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/vinmelo/Documents/Deep-Learning-Package-Inspection/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16924672 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_39582]"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate= 0.00001),\n",
    "              loss = 'binary_crossentropy', metrics=['accuracy','Precision','Recall', 'AUC'])\n",
    "\n",
    "model.fit(train_dt,\n",
    "          validation_data=valid_dt,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdba34",
   "metadata": {},
   "source": [
    "## Modelo para top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ca6651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_top = keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(320,576,3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "base_model_top.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34b79653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,715,201</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,715,201\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m513\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs_top = keras.Input(shape=(320,576,3))\n",
    "\n",
    "x_top = base_model_top(inputs_top, training=False)\n",
    "x_top = keras.layers.GlobalAveragePooling2D()(x_top)\n",
    "\n",
    "outputs_top = keras.layers.Dense(1, activation= 'sigmoid')(x_top)\n",
    "\n",
    "model_top = keras.Model(inputs_top,outputs_top)\n",
    "model_top.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "008c323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top.compile(loss = 'binary_crossentropy', metrics=['accuracy','Precision','Recall', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d7484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 2 classes.\n",
      "Using 144 files for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 2 classes.\n",
      "Using 36 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_dt_top = keras.utils.image_dataset_from_directory(\n",
    "    \"./dataset-desafio/top\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    batch_size=4,\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(320,576),\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "valid_dt_top = keras.utils.image_dataset_from_directory(\n",
    "    \"./dataset-desafio/top\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    batch_size=4,\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(320,576),\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdc9f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 319ms/step - AUC: 0.4375 - Precision: 0.3440 - Recall: 0.2181 - accuracy: 0.4327 - loss: 1.2308 - val_AUC: 0.1769 - val_Precision: 0.5200 - val_Recall: 0.5909 - val_accuracy: 0.4167 - val_loss: 0.9189\n",
      "Epoch 2/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - AUC: 0.4034 - Precision: 0.4510 - Recall: 0.4203 - accuracy: 0.4290 - loss: 0.8153 - val_AUC: 0.2354 - val_Precision: 0.3333 - val_Recall: 0.2273 - val_accuracy: 0.2500 - val_loss: 0.8868\n",
      "Epoch 3/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - AUC: 0.5126 - Precision: 0.5123 - Recall: 0.5290 - accuracy: 0.4921 - loss: 0.7384 - val_AUC: 0.2906 - val_Precision: 0.3333 - val_Recall: 0.1364 - val_accuracy: 0.3056 - val_loss: 0.8599\n",
      "Epoch 4/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 293ms/step - AUC: 0.4358 - Precision: 0.5095 - Recall: 0.4898 - accuracy: 0.4469 - loss: 0.7441 - val_AUC: 0.3636 - val_Precision: 0.2500 - val_Recall: 0.0909 - val_accuracy: 0.2778 - val_loss: 0.8276\n",
      "Epoch 5/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 294ms/step - AUC: 0.5320 - Precision: 0.5701 - Recall: 0.5401 - accuracy: 0.5496 - loss: 0.7409 - val_AUC: 0.4075 - val_Precision: 0.3333 - val_Recall: 0.0909 - val_accuracy: 0.3333 - val_loss: 0.8346\n",
      "Epoch 6/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - AUC: 0.6512 - Precision: 0.6545 - Recall: 0.6429 - accuracy: 0.6270 - loss: 0.6585 - val_AUC: 0.4529 - val_Precision: 0.6429 - val_Recall: 0.8182 - val_accuracy: 0.6111 - val_loss: 0.7069\n",
      "Epoch 7/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.6384 - Precision: 0.5674 - Recall: 0.5725 - accuracy: 0.5839 - loss: 0.6649 - val_AUC: 0.4821 - val_Precision: 0.5909 - val_Recall: 0.5909 - val_accuracy: 0.5000 - val_loss: 0.6981\n",
      "Epoch 8/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.7042 - Precision: 0.6385 - Recall: 0.7039 - accuracy: 0.6436 - loss: 0.6364 - val_AUC: 0.5519 - val_Precision: 0.6250 - val_Recall: 0.6818 - val_accuracy: 0.5556 - val_loss: 0.6748\n",
      "Epoch 9/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.7205 - Precision: 0.6712 - Recall: 0.7461 - accuracy: 0.6784 - loss: 0.6120 - val_AUC: 0.6234 - val_Precision: 0.7143 - val_Recall: 0.2273 - val_accuracy: 0.4722 - val_loss: 0.7415\n",
      "Epoch 10/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 298ms/step - AUC: 0.7501 - Precision: 0.6566 - Recall: 0.6109 - accuracy: 0.6446 - loss: 0.5813 - val_AUC: 0.6412 - val_Precision: 0.7000 - val_Recall: 0.6364 - val_accuracy: 0.6111 - val_loss: 0.6557\n",
      "Epoch 11/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 298ms/step - AUC: 0.7256 - Precision: 0.6551 - Recall: 0.6772 - accuracy: 0.6606 - loss: 0.6134 - val_AUC: 0.6786 - val_Precision: 0.7000 - val_Recall: 0.3182 - val_accuracy: 0.5000 - val_loss: 0.7048\n",
      "Epoch 12/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.7279 - Precision: 0.6874 - Recall: 0.6956 - accuracy: 0.6907 - loss: 0.6059 - val_AUC: 0.6867 - val_Precision: 0.7500 - val_Recall: 0.4091 - val_accuracy: 0.5556 - val_loss: 0.6665\n",
      "Epoch 13/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.8309 - Precision: 0.7792 - Recall: 0.8186 - accuracy: 0.7950 - loss: 0.5314 - val_AUC: 0.6981 - val_Precision: 0.7500 - val_Recall: 0.6818 - val_accuracy: 0.6667 - val_loss: 0.6172\n",
      "Epoch 14/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 461ms/step - AUC: 0.7747 - Precision: 0.7003 - Recall: 0.7587 - accuracy: 0.7165 - loss: 0.5666 - val_AUC: 0.7256 - val_Precision: 0.7857 - val_Recall: 0.5000 - val_accuracy: 0.6111 - val_loss: 0.6494\n",
      "Epoch 15/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 537ms/step - AUC: 0.8020 - Precision: 0.7048 - Recall: 0.7794 - accuracy: 0.7206 - loss: 0.5538 - val_AUC: 0.7338 - val_Precision: 0.7778 - val_Recall: 0.6364 - val_accuracy: 0.6667 - val_loss: 0.6079\n",
      "Epoch 16/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - AUC: 0.8324 - Precision: 0.7537 - Recall: 0.7794 - accuracy: 0.7698 - loss: 0.5155 - val_AUC: 0.7370 - val_Precision: 0.7600 - val_Recall: 0.8636 - val_accuracy: 0.7500 - val_loss: 0.5709\n",
      "Epoch 17/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.8236 - Precision: 0.7472 - Recall: 0.7950 - accuracy: 0.7810 - loss: 0.5149 - val_AUC: 0.7484 - val_Precision: 0.7600 - val_Recall: 0.8636 - val_accuracy: 0.7500 - val_loss: 0.5651\n",
      "Epoch 18/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 298ms/step - AUC: 0.8403 - Precision: 0.7518 - Recall: 0.7971 - accuracy: 0.7497 - loss: 0.4968 - val_AUC: 0.7532 - val_Precision: 0.8000 - val_Recall: 0.5455 - val_accuracy: 0.6389 - val_loss: 0.6449\n",
      "Epoch 19/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.7705 - Precision: 0.7624 - Recall: 0.7970 - accuracy: 0.7571 - loss: 0.5407 - val_AUC: 0.7695 - val_Precision: 0.7600 - val_Recall: 0.8636 - val_accuracy: 0.7500 - val_loss: 0.5491\n",
      "Epoch 20/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 720ms/step - AUC: 0.7860 - Precision: 0.7548 - Recall: 0.7930 - accuracy: 0.7553 - loss: 0.5308 - val_AUC: 0.7662 - val_Precision: 0.7917 - val_Recall: 0.8636 - val_accuracy: 0.7778 - val_loss: 0.5505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d10875d4850>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top.fit(train_dt_top,\n",
    "              validation_data=valid_dt_top,\n",
    "              epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 324ms/step - AUC: 0.4435 - Precision: 0.4363 - Recall: 0.1813 - accuracy: 0.4586 - loss: 1.4463 - val_AUC: 0.5584 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.3611 - val_loss: 0.9781\n",
      "Epoch 2/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - AUC: 0.4313 - Precision: 0.5206 - Recall: 0.3986 - accuracy: 0.5228 - loss: 0.8440 - val_AUC: 0.6234 - val_Precision: 0.5455 - val_Recall: 0.2727 - val_accuracy: 0.4167 - val_loss: 0.7141\n",
      "Epoch 3/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.4757 - Precision: 0.4620 - Recall: 0.4183 - accuracy: 0.4230 - loss: 0.7418 - val_AUC: 0.6688 - val_Precision: 0.7368 - val_Recall: 0.6364 - val_accuracy: 0.6389 - val_loss: 0.6555\n",
      "Epoch 4/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.6175 - Precision: 0.5472 - Recall: 0.5731 - accuracy: 0.5494 - loss: 0.6791 - val_AUC: 0.6802 - val_Precision: 0.5000 - val_Recall: 0.0455 - val_accuracy: 0.3889 - val_loss: 0.8282\n",
      "Epoch 5/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.6082 - Precision: 0.6064 - Recall: 0.4969 - accuracy: 0.5705 - loss: 0.7017 - val_AUC: 0.7273 - val_Precision: 0.7000 - val_Recall: 0.3182 - val_accuracy: 0.5000 - val_loss: 0.6650\n",
      "Epoch 6/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - AUC: 0.5755 - Precision: 0.5988 - Recall: 0.5927 - accuracy: 0.5633 - loss: 0.6819 - val_AUC: 0.7289 - val_Precision: 0.6667 - val_Recall: 0.1818 - val_accuracy: 0.4444 - val_loss: 0.7182\n",
      "Epoch 7/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 719ms/step - AUC: 0.6573 - Precision: 0.6492 - Recall: 0.5368 - accuracy: 0.6150 - loss: 0.6594 - val_AUC: 0.7484 - val_Precision: 0.7500 - val_Recall: 0.2727 - val_accuracy: 0.5000 - val_loss: 0.6978\n",
      "Epoch 8/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - AUC: 0.6775 - Precision: 0.6065 - Recall: 0.5751 - accuracy: 0.6179 - loss: 0.6438 - val_AUC: 0.7484 - val_Precision: 0.7857 - val_Recall: 0.5000 - val_accuracy: 0.6111 - val_loss: 0.6195\n",
      "Epoch 9/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 297ms/step - AUC: 0.7388 - Precision: 0.6720 - Recall: 0.6650 - accuracy: 0.6691 - loss: 0.6020 - val_AUC: 0.7549 - val_Precision: 0.7692 - val_Recall: 0.9091 - val_accuracy: 0.7778 - val_loss: 0.5548\n",
      "Epoch 10/10\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 298ms/step - AUC: 0.6807 - Precision: 0.7425 - Recall: 0.7833 - accuracy: 0.7515 - loss: 0.5680 - val_AUC: 0.7662 - val_Precision: 0.7917 - val_Recall: 0.8636 - val_accuracy: 0.7778 - val_loss: 0.5665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d1087114520>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_top.trainable = True\n",
    "\n",
    "model_top.compile(optimizer=keras.optimizers.RMSprop(learning_rate= 0.00001),\n",
    "                  loss = 'binary_crossentropy', metrics=['accuracy','Precision','Recall', 'AUC'])\n",
    "\n",
    "model.fit(train_dt_top,\n",
    "          validation_data=valid_dt_top,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c460ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
